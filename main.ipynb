{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57dea6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2ea01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the paths\n",
    "data_path = Path('data')\n",
    "cleaned_data_path = Path('cleaned_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5f424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/Beyond Good and Evil.html'),\n",
       " WindowsPath('data/ECCE HOMO.html'),\n",
       " WindowsPath('data/Human, All Too Human.html'),\n",
       " WindowsPath('data/The Antichrist.html'),\n",
       " WindowsPath('data/The Birth of Tragedy.html'),\n",
       " WindowsPath('data/The Genealogy of Morals.html'),\n",
       " WindowsPath('data/Thus Spake Zarathustra.html')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the files in the data directory\n",
    "files = list(data_path.glob(\"*.html\"))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "501eee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process, clean and save the files to the cleaned_data folder\n",
    "def clean_data(files):\n",
    "    for file in files:\n",
    "        raw_data = file.read_text(encoding='utf-8', errors='ignore')\n",
    "        soup = BeautifulSoup(raw_data, 'lxml')\n",
    "        text_data = soup.get_text(separator=\" \", strip=True)\n",
    "        cleaned_data = re.sub(r\"s\\+\", \" \", text_data)\n",
    "        cleaned_data = re.sub(r\"\\b(Pg|Page)\\.?\\s*\\d+\\b\", \"\", cleaned_data, flags=re.IGNORECASE)\n",
    "        cleaned_data = re.sub(r\"\\n      \", \" \", cleaned_data)\n",
    "        cleaned_data = cleaned_data.strip()\n",
    "        \n",
    "        path_object = cleaned_data_path/f\"{file.stem}.txt\"\n",
    "        path_object.write_text(cleaned_data, encoding='utf-8')\n",
    "        \n",
    "        print(f\"Processed {file.name} -> Saved as {path_object.name} -> {len(cleaned_data.strip())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e840ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Beyond Good and Evil.html -> Saved as Beyond Good and Evil.txt -> 400092\n",
      "Processed ECCE HOMO.html -> Saved as ECCE HOMO.txt -> 288130\n",
      "Processed Human, All Too Human.html -> Saved as Human, All Too Human.txt -> 238862\n",
      "Processed The Antichrist.html -> Saved as The Antichrist.txt -> 219159\n",
      "Processed The Birth of Tragedy.html -> Saved as The Birth of Tragedy.txt -> 345822\n",
      "Processed The Genealogy of Morals.html -> Saved as The Genealogy of Morals.txt -> 350470\n",
      "Processed Thus Spake Zarathustra.html -> Saved as Thus Spake Zarathustra.txt -> 653509\n"
     ]
    }
   ],
   "source": [
    "# Calling the clean_data function\n",
    "clean_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21d673df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all cleaned text files into a single file\n",
    "document = ''\n",
    "\n",
    "for file in list(cleaned_data_path.glob(\"*.txt\")):\n",
    "    document += f\"Start of {file.stem}  \"\n",
    "    document += file.read_text(encoding='utf-8', errors='ignore')\n",
    "    document += f\"End of {file.stem}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a640bcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424339"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words in the combined file\n",
    "len(document.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f08e900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2496426"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the combined file to the cleaned_data folder\n",
    "kb_path = cleaned_data_path/'knowledge_base.txt'\n",
    "kb_path.write_text(document, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41555570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializaing the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=['\\n\\n', '\\n', ' ', '.', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b6dd137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining knowledge_base path\n",
    "knowledge_base_path = Path(r\"cleaned_data/knowledge_base.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98472735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking the knowledge_base data\n",
    "chunks = text_splitter.split_text(knowledge_base_path.read_text(encoding='utf-8', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a3134f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3105"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of chunks generated\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "661eab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving chunks\n",
    "np.save('embeddings/chunks.npy', np.array(chunks, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fdbd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model for embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5555815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Chunks: 100%|██████████| 3105/3105 [03:57<00:00, 13.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embedding the chunks\n",
    "embeddings = []\n",
    "\n",
    "for chunk in tqdm(chunks, desc='Embedding Chunks'):\n",
    "    vector = model.encode(chunk)\n",
    "    embeddings.append(vector)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48d144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Embeddings\n",
    "np.save('embeddings/embeddings.npy', np.array(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75904fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing ChromaDB client\n",
    "client = chromadb.PersistentClient(path='chromadb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f58d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a collection in ChromaDB\n",
    "collection = client.get_or_create_collection(name='vector_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e396b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Embeddings and Chunks to the collection\n",
    "collection.add(\n",
    "    ids = [f\"chunk_{i}\" for i in range(len(chunks))],\n",
    "    embeddings = embeddings,\n",
    "    documents = chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a86a023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the retrieval of chunks\n",
    "def test(query, top_k=3):\n",
    "    embedded_query_test = model.encode(query)\n",
    "    response_test = collection.query(\n",
    "        query_embeddings=[embedded_query_test],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    return response_test['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "922fbe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nietzsche’s opus magnum, is by no means the first of Nietzsche’s works that the beginner ought to undertake to read. The author himself refers to it as the deepest work ever offered to the German public, and elsewhere speaks of his other writings as being necessary for the understanding of it. But when it is remembered that in Zarathustra we not only have the history of his most intimate experiences, friendships, feuds, disappointments, triumphs and the like, but that the very form in which they are narrated is one which tends rather to obscure than to throw light upon them, the difficulties which meet the reader who starts quite unprepared will be seen to be really formidable. Zarathustra, then,—this shadowy, allegorical personality, speaking in allegories and parables, and at times not even refraining from relating his own dreams—is a figure we can understand but very imperfectly if we have no knowledge of his creator and counterpart, Friedrich Nietzsche; and it were therefore well,',\n",
       " 'to this general effect, and later on I shall probably publish a digest\\nof them, as a contribution to the study of war hysteria. The thing went\\nto unbelievable lengths. On the strength of the fact that I had\\npublished a book on Nietzsche in 1906, six years after his death, I was\\ncalled upon by agents of the Department of Justice, elaborately\\noutfitted with badges, to meet the charge that I was an intimate\\nassociate and agent of “the German monster, Nietzsky.” I quote the\\nofficial procès verbal , an indignant but often misspelled document.\\nAlas, poor Nietzsche! After all his laborious efforts to prove that he\\nwas not a German, but a Pole—even after his heroic readiness, via\\nanti-anti-Semitism, to meet the deduction that, if a Pole, then probably\\nalso a Jew! But under all this alarmed and preposterous tosh there was at least a\\nsound instinct, and that was the instinct which recognized Nietzsche as\\nthe most eloquent, pertinacious and effective of all the critics of the',\n",
       " 'the books, and that it was thus unnecessary to rewrite them. And, having\\nan idea that seemed to him to be novel and original, he stated it in as\\nfew words as possible, and then shut down. Sometimes he got it into a\\nhundred words; sometimes it took a thousand; now and then, as in the\\npresent case, he developed a series of related ideas into a connected\\nbook. But he never wrote a word too many. He never pumped up an idea to\\nmake it appear bigger than it actually was. The pedagogues, alas, are\\nnot accustomed to that sort of writing in serious fields. They resent\\nit, and sometimes they even try to improve it. There exists, in fact, a\\nhuge and solemn tome on Nietzsche by a learned man of America in which\\nall of his brilliancy is painfully translated into the windy phrases of\\nthe seminaries. The tome is satisfactorily ponderous, but the meat of\\nthe cocoanut is left out: there is actually no discussion of the\\nNietzschean view of Christianity!... Always Nietzsche daunts the']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the test function\n",
    "test('Who was Nietzsche\\'s biggest inspiration?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850643d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
